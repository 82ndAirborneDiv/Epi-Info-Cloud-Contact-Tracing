<?xml version="1.0" encoding="utf-8"?>
<root>
  <!-- 
    Microsoft ResX Schema 
    
    Version 2.0
    
    The primary goals of this format is to allow a simple XML format 
    that is mostly human readable. The generation and parsing of the 
    various data types are done through the TypeConverter classes 
    associated with the data types.
    
    Example:
    
    ... ado.net/XML headers & schema ...
    <resheader name="resmimetype">text/microsoft-resx</resheader>
    <resheader name="version">2.0</resheader>
    <resheader name="reader">System.Resources.ResXResourceReader, System.Windows.Forms, ...</resheader>
    <resheader name="writer">System.Resources.ResXResourceWriter, System.Windows.Forms, ...</resheader>
    <data name="Name1"><value>this is my long string</value><comment>this is a comment</comment></data>
    <data name="Color1" type="System.Drawing.Color, System.Drawing">Blue</data>
    <data name="Bitmap1" mimetype="application/x-microsoft.net.object.binary.base64">
        <value>[base64 mime encoded serialized .NET Framework object]</value>
    </data>
    <data name="Icon1" type="System.Drawing.Icon, System.Drawing" mimetype="application/x-microsoft.net.object.bytearray.base64">
        <value>[base64 mime encoded string representing a byte array form of the .NET Framework object]</value>
        <comment>This is a comment</comment>
    </data>
                
    There are any number of "resheader" rows that contain simple 
    name/value pairs.
    
    Each data row contains a name, and value. The row also contains a 
    type or mimetype. Type corresponds to a .NET class that support 
    text/value conversion through the TypeConverter architecture. 
    Classes that don't support this are serialized and stored with the 
    mimetype set.
    
    The mimetype is used for serialized objects, and tells the 
    ResXResourceReader how to depersist the object. This is currently not 
    extensible. For a given mimetype the value must be set accordingly:
    
    Note - application/x-microsoft.net.object.binary.base64 is the format 
    that the ResXResourceWriter will generate, however the reader can 
    read any of the formats listed below.
    
    mimetype: application/x-microsoft.net.object.binary.base64
    value   : The object must be serialized with 
            : System.Runtime.Serialization.Formatters.Binary.BinaryFormatter
            : and then encoded with base64 encoding.
    
    mimetype: application/x-microsoft.net.object.soap.base64
    value   : The object must be serialized with 
            : System.Runtime.Serialization.Formatters.Soap.SoapFormatter
            : and then encoded with base64 encoding.

    mimetype: application/x-microsoft.net.object.bytearray.base64
    value   : The object must be serialized into a byte array 
            : using a System.ComponentModel.TypeConverter
            : and then encoded with base64 encoding.
    -->
  <xsd:schema id="root" xmlns="" xmlns:xsd="http://www.w3.org/2001/XMLSchema" xmlns:msdata="urn:schemas-microsoft-com:xml-msdata">
    <xsd:import namespace="http://www.w3.org/XML/1998/namespace" />
    <xsd:element name="root" msdata:IsDataSet="true">
      <xsd:complexType>
        <xsd:choice maxOccurs="unbounded">
          <xsd:element name="metadata">
            <xsd:complexType>
              <xsd:sequence>
                <xsd:element name="value" type="xsd:string" minOccurs="0" />
              </xsd:sequence>
              <xsd:attribute name="name" use="required" type="xsd:string" />
              <xsd:attribute name="type" type="xsd:string" />
              <xsd:attribute name="mimetype" type="xsd:string" />
              <xsd:attribute ref="xml:space" />
            </xsd:complexType>
          </xsd:element>
          <xsd:element name="assembly">
            <xsd:complexType>
              <xsd:attribute name="alias" type="xsd:string" />
              <xsd:attribute name="name" type="xsd:string" />
            </xsd:complexType>
          </xsd:element>
          <xsd:element name="data">
            <xsd:complexType>
              <xsd:sequence>
                <xsd:element name="value" type="xsd:string" minOccurs="0" msdata:Ordinal="1" />
                <xsd:element name="comment" type="xsd:string" minOccurs="0" msdata:Ordinal="2" />
              </xsd:sequence>
              <xsd:attribute name="name" type="xsd:string" use="required" msdata:Ordinal="1" />
              <xsd:attribute name="type" type="xsd:string" msdata:Ordinal="3" />
              <xsd:attribute name="mimetype" type="xsd:string" msdata:Ordinal="4" />
              <xsd:attribute ref="xml:space" />
            </xsd:complexType>
          </xsd:element>
          <xsd:element name="resheader">
            <xsd:complexType>
              <xsd:sequence>
                <xsd:element name="value" type="xsd:string" minOccurs="0" msdata:Ordinal="1" />
              </xsd:sequence>
              <xsd:attribute name="name" type="xsd:string" use="required" />
            </xsd:complexType>
          </xsd:element>
        </xsd:choice>
      </xsd:complexType>
    </xsd:element>
  </xsd:schema>
  <resheader name="resmimetype">
    <value>text/microsoft-resx</value>
  </resheader>
  <resheader name="version">
    <value>2.0</value>
  </resheader>
  <resheader name="reader">
    <value>System.Resources.ResXResourceReader, System.Windows.Forms, Version=4.0.0.0, Culture=neutral, PublicKeyToken=b77a5c561934e089</value>
  </resheader>
  <resheader name="writer">
    <value>System.Resources.ResXResourceWriter, System.Windows.Forms, Version=4.0.0.0, Culture=neutral, PublicKeyToken=b77a5c561934e089</value>
  </resheader>
  <data name="GetAllRecordsBySurveyID" xml:space="preserve">
    <value>function orderBy(filterQuery) {
    // HTTP error codes sent to our callback funciton by DocDB server.
    var ErrorCode = {
        REQUEST_ENTITY_TOO_LARGE: 413,
    }

    var collection = getContext().getCollection();
    var collectionLink = collection.getSelfLink();
    var result = new Array(); 
    tryQuery({});

    function tryQuery(options) {
        var isAccepted = (filterQuery &amp;&amp; filterQuery.length) ?
            collection.queryDocuments(collectionLink, filterQuery, options, callback) :
            collection.readDocuments(collectionLink, options, callback)

        if (!isAccepted) throw new Error("Source dataset is too large to complete the operation.");
    }

    /**
    * queryDocuments callback.
    * @param {Error} err - Error object in case of error/exception.
    * @param {Array} queryFeed - array containing results of the query.
    * @param {ResponseOptions} responseOptions.
    */
    function callback(err, queryFeed, responseOptions) {
        if (err) {
            throw err;
        }

        // Iterate over document feed and store documents into the result array.
        queryFeed.forEach(function (element, index, array) {
            result[result.length] = element;
        });    
             
            fillResponse();
    }

        // Compare two objects(documents) using field specified by the orderByFieldName parameter.
    

    // This is called in the very end on an already sorted array.
    // Sort the results and set the response body.
    function fillResponse() {
        // Main script is called with continuationToken which is the index of 1st item to start result batch from.       
        // Get/initialize the response.
        var response = getContext().getResponse();
        response.setBody(null);

        // Take care of response body getting too large:
        // Set Response iterating by one element. When we fail due to MAX response size, return to the client requesting continuation.
        var i = 0;
        // Finally, set response body.
        response.setBody({ result: result});
    }
}</value>
  </data>
  <data name="getGridContent" xml:space="preserve">
    <value>function getGridContent(query, sortKey, isSortAscending, continuationToken, skip) {
    var context = getContext();
    var response = context.getResponse();
    var collection = context.getCollection();
    var collectionLink = collection.getSelfLink();
    var responses = [];
    var nextContinuationToken;
    var currentContinuationToken;
    var responseSize = 0;
    var isMaxSizeReached = false;

    if (!sortKey) {
        sortkey = "_ts";
        isSortAscending = false;
    }

    var trace = "query:" + query + ", continuationToken:" + continuationToken + ", skip:" + skip + ", sortKey:" + sortKey + ", isSortAscending:" + isSortAscending;
    
    getNodes(continuationToken, skip);

    // continuationToken identifies the continuation point.
    // skip is then number of documents that were already returned from the continuation point.
    function getNodes(continuationToken, skip) {
        // trace = trace.concat(", getNodes");
        // Tune the pageSize to fit your dataset.
        var requestOptions =
        {
            continuation: continuationToken,
            pageSize: 100
        };

        // The number of documents taken from the current continuation block
        var taken = 0;

        var accepted = collection.queryDocuments(collectionLink, query, requestOptions,
          function (err, documentsRead, responseOptions) {
              trace = trace.concat(",queryDocments");
              currentContinuationToken = requestOptions.continuation;
              for(var thisResponse of documentsRead)
              {
                  if (skip &gt; 0) {
                      skip -= 1;
                  }
                  else {
                      // The size of the current query response page.
                      var thisResponseSize = JSON.stringify(thisResponse).length;

                      // DocumentDB has a response size limit of 1 MB.
                      if (responseSize + thisResponseSize &lt; 1024 * 1024) {
						  // Append response to responses.
                          responses = responses.concat(thisResponse);

                          // Keep track of the total response size.
                          responseSize += thisResponseSize;
                          taken += 1;
                      }
                      else {
                          isMaxSizeReached = true;
                          break;
                      }
                  }
              }
              trace = trace.concat(",taken:"+taken);

              if (!isMaxSizeReached &amp;&amp; responseOptions.continuation) {
                  // If max response size has not been reached and there is a continuation token... 
                  // Run the query again to get the next page of results
                  nextContinuationToken = responseOptions.continuation;
                  getNodes(responseOptions.continuation);
              }
              else if (isMaxSizeReached) {
                  // If the response size limit reached; run the script again with the nextContinuationToken as a script parameter.
                  response.setBody({
                      "message": "Response size limit reached.",
                      "trace": trace,
                      "continuationToken": currentContinuationToken,
                      "result": responses,
                      "skip": taken
                  });
              }
              else {
                  // If there is no continutation token, we are done. Return the response.
				  responses = schwartzianSort(responses, sortKey);
                  response.setBody({ 
                        "message" : "Completed",
                        "trace": trace,
                        "sortKey": sortKey,
                        "result": responses });
              }
          });

        if (!accepted) {
            // If the execution limit reached; run the script again with the nextContinuationToken as a script parameter.
            response.setBody({
                "message": "Execution limit reached.",
                "continuationToken": nextContinuationToken,
                "result": responses,
                "skip": taken
            });
        }
    }
	
	var schwartzianSort = (function () {
		var decorate = function (sortKey) {
			return function (item) {
				switch (sortKey) {
                    case "_ts":
						return [item["_ts"](), item];
					case "_UserEmail":
						return [item["UserName"](), item];
					case "IsDraftMode":
					case "_Mode":
						return [item.IsDraftMode, item];
					case "_DateCreated":
						return [item.FirstSaveTime, item];
					case "_DateUpdated":
						return [item.LastSaveTime, item];
					default:
						return [item.ResponseQA[sortKey] ? item.ResponseQA[sortKey].toUpperCase() : "", item];
				}
			};
		};

		var compare = function (sortFunction) {
			sortFunction = sortFunction || defaultSortFunction;

			return function (a, b) {
				return sortFunction(a[0], b[0]);
			};
		};

		var defaultSortFunction = function (a, b) {
            if (isSortAscending) {
               	if (a &lt; b) return -1;
			    if (a &gt; b) return 1;
            }
            else {
                if (a &lt; b) return 1;
                if (a &gt; b) return -1;
            }
			return 0;
		};

		var undecorate = function (item) {
			return item[1];
		};

		return function (items, sortKey, sortFunction) {
			return items.map(decorate(sortKey))
						.sort(compare(sortFunction))
						.map(undecorate);
		};
	})();
}</value>
  </data>
  <data name="udfSharingRules" xml:space="preserve">
    <value>function SharingRules(ruleId, isHostOrgUser, userOrgId, responseOrgId)
{
    switch (ruleId)
    {
        case 1:
        default:
            // Organization users can only access the data of there organization.
            return userOrgId == responseOrgId;

        case 2:
            // All users in host organization will have access to all data of all organizations
            // and other Organization users can only access the data of there organization.
            return isHostOrgUser || userOrgId == responseOrgId;

        case 3:
            // All users of all organizations can access all data.
            return true;
    }
}</value>
  </data>
  <data name="udfWildCardCompare" xml:space="preserve">
    <value>function WildCardCompare(input, pattern, singleWildcard = '?', multipleWildcard = '*')
{
    input = input.toLowerCase();
    pattern = pattern.toLowerCase();

    var inputLength = input.length;
    var patternLength = pattern.length;

    // Stack containing input positions that should be tested for further matching
    //var inputPosStack = new int[(input.Length + 1) * (pattern.Length + 1)];
    var inputPosStack = [];

    // Stack containing pattern positions that should be tested for further matching
    //var patternPosStack = new int[inputPosStack.Length];                      
    var patternPosStack = [];

    // Each true value indicates that input position vs. pattern position has been tested	
    //var pointTested = new bool[input.Length + 1, pattern.Length + 1];       	
    var pointTested = [];
    for (var i = 0; i &lt; input.length+1; i++) 
    {
        pointTested[i] = [];
        for (var p = 0; p &lt; pattern.length+1; p++) 
        {
            pointTested[i][p] = false;
        }
    }

    // Points to last occupied entry in stack; -1 indicates that stack is empty
    var stackPos = -1;  

    // Position in input matched up to the first multiple wildcard in pattern
    var inputPos = 0;   

    // Position in pattern matched up to the first multiple wildcard in pattern
    var patternPos = 0; 

    // Match beginning of the string until first multiple wildcard in pattern
    while (inputPos &lt; inputLength &amp;&amp; patternPos &lt; patternLength &amp;&amp; pattern[patternPos] != multipleWildcard &amp;&amp; (input[inputPos] == pattern[patternPos] || pattern[patternPos] == singleWildcard))
    {
        inputPos++;
        patternPos++;
    }

    // Push this position to stack if it points to end of pattern or to a general wildcard
    if (patternPos == patternLength || pattern[patternPos] == multipleWildcard)
    {
        pointTested[inputPos][patternPos] = true;
        inputPosStack[++stackPos] = inputPos;
        patternPosStack[stackPos] = patternPos;
    }

    var isMatched = false;

    // Repeat matching until either string is matched against the pattern or no more parts remain on stack to test
    while (stackPos &gt;= 0 &amp;&amp; !isMatched)
    {
        // Pop input and pattern positions from stack
        inputPos = inputPosStack[stackPos];  
	
        // Matching will succeed if rest of the input string matches rest of the pattern
        patternPos = patternPosStack[stackPos--];
	
        if (inputPos == inputLength &amp;&amp; (patternPos == patternLength || patternPos == patternLength-1 &amp;&amp; pattern[patternPos] == multipleWildcard))
        {
            // Reached end of both pattern and input string, hence matching is successful
            isMatched = true;     
        }
        else
        {
            // First character in next pattern block is guaranteed to be multiple wildcard
            // So skip it and search for all matches in value string until next multiple wildcard character is reached in pattern
            for (var curInputStart = inputPos; curInputStart &lt; inputLength; curInputStart++)
            {
                var curInputPos = curInputStart;
                var curPatternPos = patternPos + 1;
                if (curPatternPos == patternLength)
                {   
                    // Pattern ends with multiple wildcard, hence rest of the input string is matched with that character
                    curInputPos = inputLength;
                }
                else
                {
                    while (curInputPos &lt; inputLength &amp;&amp; curPatternPos &lt; patternLength &amp;&amp; pattern[curPatternPos] != multipleWildcard &amp;&amp;
                        (input[curInputPos] == pattern[curPatternPos] || pattern[curPatternPos] == singleWildcard))
                    {
                        curInputPos++;
                        curPatternPos++;
                    }
                }

                // If we have reached next multiple wildcard character in pattern without breaking the matching sequence, then we have another candidate for full match
                // This candidate should be pushed to stack for further processing
                // At the same time, pair (input position, pattern position) will be marked as tested, so that it will not be pushed to stack later again
                if (((curPatternPos == patternLength &amp;&amp; curInputPos == inputLength) || (curPatternPos &lt; patternLength &amp;&amp; pattern[curPatternPos] == multipleWildcard))
                    &amp;&amp; !pointTested[curInputPos][curPatternPos])
                {
                    pointTested[curInputPos][curPatternPos] = true;
                    inputPosStack[++stackPos] = curInputPos;
                    patternPosStack[stackPos] = curPatternPos;
                }
            }
        }
    }
    return isMatched;
}</value>
  </data>
</root>