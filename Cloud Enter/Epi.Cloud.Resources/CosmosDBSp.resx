<?xml version="1.0" encoding="utf-8"?>
<root>
  <!-- 
    Microsoft ResX Schema 
    
    Version 2.0
    
    The primary goals of this format is to allow a simple XML format 
    that is mostly human readable. The generation and parsing of the 
    various data types are done through the TypeConverter classes 
    associated with the data types.
    
    Example:
    
    ... ado.net/XML headers & schema ...
    <resheader name="resmimetype">text/microsoft-resx</resheader>
    <resheader name="version">2.0</resheader>
    <resheader name="reader">System.Resources.ResXResourceReader, System.Windows.Forms, ...</resheader>
    <resheader name="writer">System.Resources.ResXResourceWriter, System.Windows.Forms, ...</resheader>
    <data name="Name1"><value>this is my long string</value><comment>this is a comment</comment></data>
    <data name="Color1" type="System.Drawing.Color, System.Drawing">Blue</data>
    <data name="Bitmap1" mimetype="application/x-microsoft.net.object.binary.base64">
        <value>[base64 mime encoded serialized .NET Framework object]</value>
    </data>
    <data name="Icon1" type="System.Drawing.Icon, System.Drawing" mimetype="application/x-microsoft.net.object.bytearray.base64">
        <value>[base64 mime encoded string representing a byte array form of the .NET Framework object]</value>
        <comment>This is a comment</comment>
    </data>
                
    There are any number of "resheader" rows that contain simple 
    name/value pairs.
    
    Each data row contains a name, and value. The row also contains a 
    type or mimetype. Type corresponds to a .NET class that support 
    text/value conversion through the TypeConverter architecture. 
    Classes that don't support this are serialized and stored with the 
    mimetype set.
    
    The mimetype is used for serialized objects, and tells the 
    ResXResourceReader how to depersist the object. This is currently not 
    extensible. For a given mimetype the value must be set accordingly:
    
    Note - application/x-microsoft.net.object.binary.base64 is the format 
    that the ResXResourceWriter will generate, however the reader can 
    read any of the formats listed below.
    
    mimetype: application/x-microsoft.net.object.binary.base64
    value   : The object must be serialized with 
            : System.Runtime.Serialization.Formatters.Binary.BinaryFormatter
            : and then encoded with base64 encoding.
    
    mimetype: application/x-microsoft.net.object.soap.base64
    value   : The object must be serialized with 
            : System.Runtime.Serialization.Formatters.Soap.SoapFormatter
            : and then encoded with base64 encoding.

    mimetype: application/x-microsoft.net.object.bytearray.base64
    value   : The object must be serialized into a byte array 
            : using a System.ComponentModel.TypeConverter
            : and then encoded with base64 encoding.
    -->
  <xsd:schema id="root" xmlns="" xmlns:xsd="http://www.w3.org/2001/XMLSchema" xmlns:msdata="urn:schemas-microsoft-com:xml-msdata">
    <xsd:import namespace="http://www.w3.org/XML/1998/namespace" />
    <xsd:element name="root" msdata:IsDataSet="true">
      <xsd:complexType>
        <xsd:choice maxOccurs="unbounded">
          <xsd:element name="metadata">
            <xsd:complexType>
              <xsd:sequence>
                <xsd:element name="value" type="xsd:string" minOccurs="0" />
              </xsd:sequence>
              <xsd:attribute name="name" use="required" type="xsd:string" />
              <xsd:attribute name="type" type="xsd:string" />
              <xsd:attribute name="mimetype" type="xsd:string" />
              <xsd:attribute ref="xml:space" />
            </xsd:complexType>
          </xsd:element>
          <xsd:element name="assembly">
            <xsd:complexType>
              <xsd:attribute name="alias" type="xsd:string" />
              <xsd:attribute name="name" type="xsd:string" />
            </xsd:complexType>
          </xsd:element>
          <xsd:element name="data">
            <xsd:complexType>
              <xsd:sequence>
                <xsd:element name="value" type="xsd:string" minOccurs="0" msdata:Ordinal="1" />
                <xsd:element name="comment" type="xsd:string" minOccurs="0" msdata:Ordinal="2" />
              </xsd:sequence>
              <xsd:attribute name="name" type="xsd:string" use="required" msdata:Ordinal="1" />
              <xsd:attribute name="type" type="xsd:string" msdata:Ordinal="3" />
              <xsd:attribute name="mimetype" type="xsd:string" msdata:Ordinal="4" />
              <xsd:attribute ref="xml:space" />
            </xsd:complexType>
          </xsd:element>
          <xsd:element name="resheader">
            <xsd:complexType>
              <xsd:sequence>
                <xsd:element name="value" type="xsd:string" minOccurs="0" msdata:Ordinal="1" />
              </xsd:sequence>
              <xsd:attribute name="name" type="xsd:string" use="required" />
            </xsd:complexType>
          </xsd:element>
        </xsd:choice>
      </xsd:complexType>
    </xsd:element>
  </xsd:schema>
  <resheader name="resmimetype">
    <value>text/microsoft-resx</value>
  </resheader>
  <resheader name="version">
    <value>2.0</value>
  </resheader>
  <resheader name="reader">
    <value>System.Resources.ResXResourceReader, System.Windows.Forms, Version=4.0.0.0, Culture=neutral, PublicKeyToken=b77a5c561934e089</value>
  </resheader>
  <resheader name="writer">
    <value>System.Resources.ResXResourceWriter, System.Windows.Forms, Version=4.0.0.0, Culture=neutral, PublicKeyToken=b77a5c561934e089</value>
  </resheader>
  <data name="GetAllRecordsBySurveyID" xml:space="preserve">
    <value>function orderBy(filterQuery) {
    // HTTP error codes sent to our callback funciton by DocDB server.
    var ErrorCode = {
        REQUEST_ENTITY_TOO_LARGE: 413,
    }

    var collection = getContext().getCollection();
    var collectionLink = collection.getSelfLink();
    var result = new Array(); 
    tryQuery({});

    function tryQuery(options) {
        var isAccepted = (filterQuery &amp;&amp; filterQuery.length) ?
            collection.queryDocuments(collectionLink, filterQuery, options, callback) :
            collection.readDocuments(collectionLink, options, callback)

        if (!isAccepted) throw new Error("Source dataset is too large to complete the operation.");
    }

    /**
    * queryDocuments callback.
    * @param {Error} err - Error object in case of error/exception.
    * @param {Array} queryFeed - array containing results of the query.
    * @param {ResponseOptions} responseOptions.
    */
    function callback(err, queryFeed, responseOptions) {
        if (err) {
            throw err;
        }

        // Iterate over document feed and store documents into the result array.
        queryFeed.forEach(function (element, index, array) {
            result[result.length] = element;
        });    
             
            fillResponse();
    }

        // Compare two objects(documents) using field specified by the orderByFieldName parameter.
    

    // This is called in the very end on an already sorted array.
    // Sort the results and set the response body.
    function fillResponse() {
        // Main script is called with continuationToken which is the index of 1st item to start result batch from.       
        // Get/initialize the response.
        var response = getContext().getResponse();
        response.setBody(null);

        // Take care of response body getting too large:
        // Set Response iterating by one element. When we fail due to MAX response size, return to the client requesting continuation.
        var i = 0;
        // Finally, set response body.
        response.setBody({ result: result});
    }
}</value>
  </data>
  <data name="OrderBy" xml:space="preserve">
    <value>function orderBy(relateParentId,formId,recStatus, orderByFieldName, continuationToken) {
    // HTTP error codes sent to our callback funciton by DocDB server.
    var ErrorCode = {
        REQUEST_ENTITY_TOO_LARGE: 413,
    }    
    var collection = getContext().getCollection();
    var collectionLink = collection.getSelfLink();
    var result = new Array();
     
    if(relateParentId){
            var filterQuery="SELECT * FROM c where c.RelateParentId='"+relateParentId+"'                                  and c.FormId='"+formId+"' and c.RecStatus !="+recStatus;
    }
    else{
            var filterQuery="SELECT * FROM c where c.FormId='"+formId+"' and c.RecStatus !="                              +recStatus;
    }
    tryQuery({});

    function tryQuery(options) {
        var isAccepted = (filterQuery &amp;&amp; filterQuery.length) ?
            collection.queryDocuments(collectionLink, filterQuery, options, callback) :
            collection.readDocuments(collectionLink, options, callback)

        if (!isAccepted) throw new Error("Source dataset is too large to complete the operation.");
    }

    /**
    * queryDocuments callback.
    * @param {Error} err - Error object in case of error/exception.
    * @param {Array} queryFeed - array containing results of the query.
    * @param {ResponseOptions} responseOptions.
    */
    function callback(err, queryFeed, responseOptions) {
        if (err) {
            throw err;
        }

        // Iterate over document feed and store documents into the result array.
        queryFeed.forEach(function (element, index, array) {
            result[result.length] = element;
        });

        if (responseOptions.continuation) {
            // If there is continuation, call query again providing continuation token.
            tryQuery({ continuation: responseOptions.continuation });
        } else {
            // We are done with querying/got all results. Sort the results and return from the script.
       

            fillResponse();
        }
    }

    

    // This is called in the very end on an already sorted array.
    // Sort the results and set the response body.
    function fillResponse() {
        // Main script is called with continuationToken which is the index of 1st item to start result batch from.
        // Slice the result array and discard the beginning. From now on use the 'continuationResult' var.
        var continuationResult = result;
        if (continuationToken) continuationResult = result.slice(continuationToken);
        else continuationToken = 0;

        // Get/initialize the response.
        var response = getContext().getResponse();
        response.setBody(null);

        // Take care of response body getting too large:
        // Set Response iterating by one element. When we fail due to MAX response size, return to the client requesting continuation.
        var i = 0;
        for (; i &lt; continuationResult.length; ++i) {
            try {
                // Note: setBody is very expensive vs appendBody, use appendBody with simple approximation JSON.stringify(element).
                response.appendBody(JSON.stringify(continuationResult[i]));
            } catch (ex) {
                if (!ex.number == ErrorCode.REQUEST_ENTITY_TOO_LARGE) throw ex;
                break;
            }
        }
        
        // Now next batch to return to client has i elements.
        // Slice the continuationResult if needed and discard the end.
        var partialResult = continuationResult;
        var newContinuation = null;
        if (i &lt; continuationResult.length) {
            partialResult = continuationResult.slice(0, i);
        }

        // Finally, set response body.
        response.setBody({ result: result, continuation: newContinuation });
    }
}</value>
  </data>
  <data name="udfSharingRules" xml:space="preserve">
    <value>function SharingRules(ruleId, isHostOrgUser, userOrgId, responseOrgId)
{
    switch (ruleId)
    {
        case 1:
        default:
            // Organization users can only access the data of there organization.
            return userOrgId == responseOrgId;

        case 2:
            // All users in host organization will have access to all data of all organizations
            // and other Organization users can only access the data of there organization.
            return isHostOrgUser || userOrgId == responseOrgId;

        case 3:
            // All users of all organizations can access all data.
            return true;
    }
}</value>
  </data>
  <data name="udfWildCardCompare" xml:space="preserve">
    <value>function WildCardCompare(input, pattern, singleWildcard = '?', multipleWildcard = '*')
{
    input = input.toLowerCase();
    pattern = pattern.toLowerCase();

    var inputLength = input.length;
    var patternLength = pattern.length;

    // Stack containing input positions that should be tested for further matching
    //var inputPosStack = new int[(input.Length + 1) * (pattern.Length + 1)];
    var inputPosStack = [];

    // Stack containing pattern positions that should be tested for further matching
    //var patternPosStack = new int[inputPosStack.Length];                      
    var patternPosStack = [];

    // Each true value indicates that input position vs. pattern position has been tested	
    //var pointTested = new bool[input.Length + 1, pattern.Length + 1];       	
    var pointTested = [];
    for (var i = 0; i &lt; input.length+1; i++) 
    {
        pointTested[i] = [];
        for (var p = 0; p &lt; pattern.length+1; p++) 
        {
            pointTested[i][p] = false;
        }
    }

    // Points to last occupied entry in stack; -1 indicates that stack is empty
    var stackPos = -1;  

    // Position in input matched up to the first multiple wildcard in pattern
    var inputPos = 0;   

    // Position in pattern matched up to the first multiple wildcard in pattern
    var patternPos = 0; 

    // Match beginning of the string until first multiple wildcard in pattern
    while (inputPos &lt; inputLength &amp;&amp; patternPos &lt; patternLength &amp;&amp; pattern[patternPos] != multipleWildcard &amp;&amp; (input[inputPos] == pattern[patternPos] || pattern[patternPos] == singleWildcard))
    {
        inputPos++;
        patternPos++;
    }

    // Push this position to stack if it points to end of pattern or to a general wildcard
    if (patternPos == patternLength || pattern[patternPos] == multipleWildcard)
    {
        pointTested[inputPos][patternPos] = true;
        inputPosStack[++stackPos] = inputPos;
        patternPosStack[stackPos] = patternPos;
    }

    var isMatched = false;

    // Repeat matching until either string is matched against the pattern or no more parts remain on stack to test
    while (stackPos &gt;= 0 &amp;&amp; !isMatched)
    {
        // Pop input and pattern positions from stack
        inputPos = inputPosStack[stackPos];  
	
        // Matching will succeed if rest of the input string matches rest of the pattern
        patternPos = patternPosStack[stackPos--];
	
        if (inputPos == inputLength &amp;&amp; (patternPos == patternLength || patternPos == patternLength-1 &amp;&amp; pattern[patternPos] == multipleWildcard))
        {
            // Reached end of both pattern and input string, hence matching is successful
            isMatched = true;     
        }
        else
        {
            // First character in next pattern block is guaranteed to be multiple wildcard
            // So skip it and search for all matches in value string until next multiple wildcard character is reached in pattern
            for (var curInputStart = inputPos; curInputStart &lt; inputLength; curInputStart++)
            {
                var curInputPos = curInputStart;
                var curPatternPos = patternPos + 1;
                if (curPatternPos == patternLength)
                {   
                    // Pattern ends with multiple wildcard, hence rest of the input string is matched with that character
                    curInputPos = inputLength;
                }
                else
                {
                    while (curInputPos &lt; inputLength &amp;&amp; curPatternPos &lt; patternLength &amp;&amp; pattern[curPatternPos] != multipleWildcard &amp;&amp;
                        (input[curInputPos] == pattern[curPatternPos] || pattern[curPatternPos] == singleWildcard))
                    {
                        curInputPos++;
                        curPatternPos++;
                    }
                }

                // If we have reached next multiple wildcard character in pattern without breaking the matching sequence, then we have another candidate for full match
                // This candidate should be pushed to stack for further processing
                // At the same time, pair (input position, pattern position) will be marked as tested, so that it will not be pushed to stack later again
                if (((curPatternPos == patternLength &amp;&amp; curInputPos == inputLength) || (curPatternPos &lt; patternLength &amp;&amp; pattern[curPatternPos] == multipleWildcard))
                    &amp;&amp; !pointTested[curInputPos][curPatternPos])
                {
                    pointTested[curInputPos][curPatternPos] = true;
                    inputPosStack[++stackPos] = curInputPos;
                    patternPosStack[stackPos] = curPatternPos;
                }
            }
        }
    }
    return isMatched;
}</value>
  </data>
</root>